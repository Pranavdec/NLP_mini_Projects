{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdGVqprbbJ-g"
      },
      "source": [
        "# Named Entity Recognition with Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3GQ3nlZWclJL",
        "outputId": "e44a018b-3854-42b5-a79e-ad894661c48f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Sentence #           Word  POS Tag\n",
              "0           0  Sentence: 1      Thousands  NNS   O\n",
              "1           1  Sentence: 1             of   IN   O\n",
              "2           2  Sentence: 1  demonstrators  NNS   O\n",
              "3           3  Sentence: 1           have  VBP   O\n",
              "4           4  Sentence: 1        marched  VBN   O"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load data\n",
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ojPYJ727cxCE"
      },
      "outputs": [],
      "source": [
        "#Creating a function to make filter the token and tag data\n",
        "#importing itertools library\n",
        "from itertools import chain\n",
        "def make_dict_map(data, tokentag):\n",
        "    # Define dictionaries to store the mapping between tokens/tags and indices\n",
        "    token_to_idx = {}\n",
        "    idx_to_token = {}\n",
        "\n",
        "    # Check which data to filter (token or tag)\n",
        "    if tokentag == 'token':\n",
        "        voc = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        voc = list(set(data['Tag'].to_list()))\n",
        "\n",
        "    # Create mappings for both directions: index to token/tag and token/tag to index\n",
        "    idx_to_token = {idx:tok for  idx, tok in enumerate(voc)}\n",
        "    token_to_idx = {tok:idx for  idx, tok in enumerate(voc)}\n",
        "\n",
        "    return token_to_idx , idx_to_token\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y74ZNshzsBiG"
      },
      "outputs": [],
      "source": [
        "#Filtering the token and tag using make_dict_map function\n",
        "token_to_idx, idx_to_token = make_dict_map(data, 'token')\n",
        "tag_to_idx, idx_to_tag = make_dict_map(data, 'tag')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4aJnRcKzeIqp"
      },
      "outputs": [],
      "source": [
        "#mapping the data with token and tag\n",
        "data['Word_idx'] = data['Word'].map(token_to_idx)\n",
        "data['Tag_idx'] = data['Tag'].map(tag_to_idx)\n",
        "#Filling the Nan values in the dataset\n",
        "data_fillna = data.fillna(method='ffill', axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tvMxr6B65ii",
        "outputId": "ac8c74b8-5581-4577-f3fd-8a71422dbc3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\palle\\AppData\\Local\\Temp\\ipykernel_15236\\3689941710.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  data_group = data_fillna.groupby(['Sentence #'],as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n"
          ]
        }
      ],
      "source": [
        "# Groupby and collect columns\n",
        "data_group = data_fillna.groupby(['Sentence #'],as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "NETe3oCz7r0Z",
        "outputId": "5844ca20-32b7-4502-d71c-74ace86ef75c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
              "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
              "      <td>[15650, 17125, 14468, 31372, 5460, 31866, 2086...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 4, 15, 15, 15, 15, 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 10</td>\n",
              "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
              "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
              "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[8222, 8893, 30383, 31571, 30967, 30415, 6316,...</td>\n",
              "      <td>[5, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 100</td>\n",
              "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
              "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
              "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
              "      <td>[22742, 31083, 2479, 16677, 29170, 6603, 28220...</td>\n",
              "      <td>[15, 15, 14, 15, 15, 15, 15, 15, 4, 15, 15, 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1000</td>\n",
              "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
              "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[7293, 6699, 15495, 1243, 20312, 3816, 23225, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 10000</td>\n",
              "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
              "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
              "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
              "      <td>[6865, 22555, 1486, 4745, 13328, 27200, 17230,...</td>\n",
              "      <td>[4, 15, 15, 6, 10, 15, 14, 15, 4, 15, 5, 15, 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #                                               Word  \\\n",
              "0      Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
              "1     Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
              "2    Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
              "3   Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
              "4  Sentence: 10000  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
              "\n",
              "                                                 POS  \\\n",
              "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
              "1  [JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...   \n",
              "2  [NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...   \n",
              "3     [PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]   \n",
              "4  [NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...   \n",
              "\n",
              "                                                 Tag  \\\n",
              "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
              "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...   \n",
              "3                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
              "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...   \n",
              "\n",
              "                                            Word_idx  \\\n",
              "0  [15650, 17125, 14468, 31372, 5460, 31866, 2086...   \n",
              "1  [8222, 8893, 30383, 31571, 30967, 30415, 6316,...   \n",
              "2  [22742, 31083, 2479, 16677, 29170, 6603, 28220...   \n",
              "3  [7293, 6699, 15495, 1243, 20312, 3816, 23225, ...   \n",
              "4  [6865, 22555, 1486, 4745, 13328, 27200, 17230,...   \n",
              "\n",
              "                                             Tag_idx  \n",
              "0  [15, 15, 15, 15, 15, 15, 4, 15, 15, 15, 15, 15...  \n",
              "1  [5, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15...  \n",
              "2  [15, 15, 14, 15, 15, 15, 15, 15, 4, 15, 15, 15...  \n",
              "3       [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]  \n",
              "4  [4, 15, 15, 6, 10, 15, 14, 15, 4, 15, 5, 15, 5...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_group.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5guDSqlm8G5Z"
      },
      "outputs": [],
      "source": [
        "#Importing train_test_split to split the training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Importing libraries from keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0rHOJ8R6eKH7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the data into training, testing, and validation sets\n",
        "\n",
        "def get_train_test_val(data_group, datas):\n",
        "\n",
        "   # Create a list of token indices and pad to the maximum length \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    #getting the maximum token length and tag length\n",
        "    ntoken = len(list(set(datas['Word'].to_list())))\n",
        "    ntag = len(list(set(datas['Tag'].to_list())))\n",
        "    \n",
        "    padtokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= ntoken - 1)\n",
        "    # Create a list of tag indices, pad to the maximum length, and convert to one-hot encoding\n",
        "    tags = data_group['Tag_idx'].tolist()\n",
        "    padtags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag_to_idx[\"O\"])\n",
        "    ntags = len(tag_to_idx)\n",
        "    padtags = [to_categorical(i, num_classes=ntags) for i in padtags]\n",
        "    \n",
        "    #Splitting the train, test and validation set\n",
        "    tokens, testtokens, tags, testtags = train_test_split(padtokens, padtags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    traintokens, valtokens, traintags, valtags = train_test_split(tokens,tags,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'length of train tokens :', len(traintokens),\n",
        "        '\\nlength of train tags   :', len(traintags),\n",
        "        '\\nlength of test tokens  :', len(testtokens),\n",
        "        '\\nlength of test tags    :', len(testtags),\n",
        "        '\\nlength of val tokens   :', len(valtokens),\n",
        "        '\\nlength of val tags     :', len(valtags),\n",
        "    )\n",
        "    \n",
        "    # Print length of each set\n",
        "    return traintokens, testtokens, valtokens, traintags,testtags,valtags\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTnXOPA--ctH",
        "outputId": "b1becd27-f15b-4202-a689-55dc20abf2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of train tokens : 32372 \n",
            "length of train tags   : 32372 \n",
            "length of test tokens  : 4796 \n",
            "length of test tags    : 4796 \n",
            "length of val tokens   : 10791 \n",
            "length of val tags     : 10791\n"
          ]
        }
      ],
      "source": [
        "#printing the lengths of train_tokens, test_tokens, val_tokens, train_tags,test_tags,val_tags\n",
        "traintokens, testtokens, valtokens, traintags,testtags,valtags= get_train_test_val(data_group, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tvkuSczWikRQ"
      },
      "outputs": [],
      "source": [
        "#Importing numpy library and tensorflow.keras library for model building.\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tensorflow.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SdoSRoMninws"
      },
      "outputs": [],
      "source": [
        "#Finding the input and output dimension for Data\n",
        "input_dim = len(list(set(data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0US9_kewJNim",
        "outputId": "98d92884-cf5b-45e4-af75-3b4f03c75369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Finding the length of tag_to_idx and saving in ntags variable\n",
        "ntags = len(tag_to_idx)\n",
        "ntags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D4Xc8wGfklFG"
      },
      "outputs": [],
      "source": [
        "# Function for defining the architecture of the model\n",
        "def get_bilstmlstm():\n",
        "    # Selecting a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Adding an Embedding layer to the model\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "    \n",
        "    # Adding a bidirectional LSTM layer to the model\n",
        "    # The 'Bidirectional' layer runs the LSTM layer in both forward and backward directions, effectively providing information from the past and future context\n",
        "    # 'units' is the number of LSTM cells to use in the layer\n",
        "    # 'return_sequences' indicates whether the LSTM layer should return the output for each time step or just the final time step\n",
        "    # 'dropout' is a regularization method to prevent overfitting in the model\n",
        "    # 'recurrent_dropout' is a dropout method for the recurrent connections in the LSTM cells\n",
        "    # 'merge_mode' is the mode used to merge the forward and backward outputs from the LSTM layer\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Adding an LSTM layer to the model\n",
        "    # This layer is similar to the bidirectional LSTM layer, but only runs in one direction\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Adding a TimeDistributed layer to the model\n",
        "    # The 'TimeDistributed' layer applies a dense layer to each time step in the input\n",
        "    model.add(TimeDistributed(Dense(ntags, activation=\"relu\")))\n",
        "\n",
        "    # Compiling the model with categorical crossentropy loss and the Adam optimizer\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Displaying a summary of the model architecture\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have chosen the Bi-LSTM model because it is a powerful deep learning architecture that can handle sequential data such as text data. This type of model is designed to handle sequences where the order of the data is important, which is the case with text data where the order of words can impact the meaning of a sentence.\n",
        "\n",
        "Additionally, the Bi-LSTM model is designed to handle bidirectional data, meaning it can learn patterns in the data from both forward and backward sequences. This is important in NLP tasks, where information from both the previous and next words can impact the meaning of a given word.\n",
        "\n",
        "The LSTM part of the Bi-LSTM model also helps to prevent the vanishing gradient problem, which is a common issue in deep learning models that can cause the model to stop learning over time. The LSTM part of the model can store information from earlier in the sequence, which helps the model to continue learning even when it is processing data that is far away from the start of the sequence.\n",
        "\n",
        "Overall, the Bi-LSTM model is well-suited for NLP tasks, especially tasks that require the model to handle sequential data and to take into account both forward and backward sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ynmGIxkzuU",
        "outputId": "7429bc45-3d3d-49ba-cdcc-1e2aa5d33b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 104, 64)           2251456   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 104, 128)         66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 104, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 104, 17)          1105      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,368,017\n",
            "Trainable params: 2,368,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.8933 - accuracy: 0.9301\n",
            "Epoch 1: val_loss improved from inf to 0.30129, saving model to best_weights.h5\n",
            "26/26 [==============================] - 148s 5s/step - loss: 0.8933 - accuracy: 0.9301 - val_loss: 0.3013 - val_accuracy: 0.9681 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.9677\n",
            "Epoch 2: val_loss improved from 0.30129 to 0.25541, saving model to best_weights.h5\n",
            "26/26 [==============================] - 181s 7s/step - loss: 0.2993 - accuracy: 0.9677 - val_loss: 0.2554 - val_accuracy: 0.9681 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9677\n",
            "Epoch 3: val_loss improved from 0.25541 to 0.23266, saving model to best_weights.h5\n",
            "26/26 [==============================] - 199s 8s/step - loss: 0.2632 - accuracy: 0.9677 - val_loss: 0.2327 - val_accuracy: 0.9681 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9677\n",
            "Epoch 4: val_loss improved from 0.23266 to 0.20772, saving model to best_weights.h5\n",
            "26/26 [==============================] - 215s 8s/step - loss: 0.2312 - accuracy: 0.9677 - val_loss: 0.2077 - val_accuracy: 0.9681 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9677\n",
            "Epoch 5: val_loss improved from 0.20772 to 0.19749, saving model to best_weights.h5\n",
            "26/26 [==============================] - 221s 9s/step - loss: 0.2151 - accuracy: 0.9677 - val_loss: 0.1975 - val_accuracy: 0.9681 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x16f44505700>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Initialize the model\n",
        "model_bilstm = get_bilstmlstm()\n",
        "\n",
        "# Adding checkpoint to save the best weights\n",
        "checkpoint = ModelCheckpoint(\"best_weights.h5\", save_best_only=True, verbose=1)\n",
        "\n",
        "# Adding learning rate reduction\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1)\n",
        "\n",
        "# Save the architecture of the model\n",
        "model_bilstm.save(\"model_architecture.h5\")\n",
        "\n",
        "# Fit the model with checkpoint and reduce_lr callbacks\n",
        "model_bilstm.fit(traintokens, np.array(traintags), batch_size=1000, verbose=1, epochs=5, \n",
        "                 validation_split=0.2, callbacks=[checkpoint, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 9s 57ms/step - loss: 0.1966 - accuracy: 0.9680\n",
            "Accuracy: 96.80%\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the best weights from training\n",
        "model_bilstm.load_weights('best_weights.h5')\n",
        "\n",
        "# Evaluation on test data\n",
        "scores = model_bilstm.evaluate(testtokens, np.array(testtags), verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NameEnitityRecognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
